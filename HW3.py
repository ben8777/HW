# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18hbExYrCWBJOVseVS2weAeas2bYyTieL
"""



from google.colab import files
uploaded = files.upload()

import json
import gzip
import re
import requests
from IPython.display import display, HTML

# Task 20: Read the JSON Document
def read_wiki_article(filename, article_title):
    print("--- Task 20: Read the JSON Document ---")

    with gzip.open(filename, 'rt', encoding='utf-8') as file:
        for line in file:
            article = json.loads(line.strip())
            if article['title'] == article_title:
                print(f"Found article: {article_title}")
                return article

    print(f"Article '{article_title}' not found")
    return None

# Task 21: Extract Lines Containing Category Names
def extract_category_lines(article_text):
    print("\n--- Task 21: Extract Lines Containing Category Names ---")
    category_pattern = re.compile(r'.*\[\[Category:.*?\]\].*')
    category_lines = category_pattern.findall(article_text)

    for line in category_lines:
        print(line)

    return category_lines

# Task 22: Extract Category Names
def extract_category_names(category_lines):
    print("\n--- Task 22: Extract Category Names ---")
    category_name_pattern = re.compile(r'\[\[Category:(.*?)(?:\|.*?)?\]\]')
    category_names = []

    for line in category_lines:
        names = category_name_pattern.findall(line)
        category_names.extend(names)

    for name in category_names:
        print(name)

    return category_names

# Task 23: Section Structure
def extract_section_structure(article_text):
    print("\n--- Task 23: Section Structure ---")
    section_pattern = re.compile(r'(={2,6})(.*?)\1')
    sections = section_pattern.findall(article_text)

    section_info = []
    for section_markers, section_name in sections:
        level = len(section_markers) // 2
        clean_name = section_name.strip()
        section_info.append((clean_name, level))
        print(f"Section: '{clean_name}', Level: {level}")

    return section_info

# Task 24: Extract Multimedia References
def extract_multimedia(article_text):
    print("\n--- Task 24: Extract Multimedia References ---")
    multimedia_pattern = re.compile(r'\[\[(File|Image):([^|\]]+)[^\]]*\]\]')
    multimedia_files = multimedia_pattern.findall(article_text)

    result = [file[1] for file in multimedia_files]
    for file in result:
        print(file)

    return result

# Task 25: Extract Infobox Information
def extract_infobox(article_text):
    print("\n--- Task 25: Extract Infobox Information ---")
    infobox_pattern = re.compile(r'{{Infobox country(.*?)}}', re.DOTALL)
    infobox_match = infobox_pattern.search(article_text)

    if not infobox_match:
        print("No Infobox found")
        return {}

    infobox_content = infobox_match.group(1)

    # Extract field names and values
    field_pattern = re.compile(r'\|\s*([^=]+?)\s*=\s*(.*?)(?=\n\||\n}})', re.DOTALL)
    fields = field_pattern.findall(infobox_content)

    infobox_dict = {}
    for field_name, field_value in fields:
        field_name = field_name.strip()
        field_value = field_value.strip()
        infobox_dict[field_name] = field_value
        print(f"{field_name}: {field_value[:100]}..." if len(field_value) > 100 else f"{field_name}: {field_value}")

    return infobox_dict

# Task 26: Remove Emphasis Tags
def remove_emphasis_tags(infobox_dict):
    print("\n--- Task 26: Remove Emphasis Tags ---")
    cleaned_dict = {}

    emphasis_pattern = re.compile(r"'{2,5}(.*?)'{2,5}")

    for key, value in infobox_dict.items():
        cleaned_value = emphasis_pattern.sub(r'\1', value)
        cleaned_dict[key] = cleaned_value
        print(f"{key}: {cleaned_value[:100]}..." if len(cleaned_value) > 100 else f"{key}: {cleaned_value}")

    return cleaned_dict

# Task 27: Remove Internal Link Tags
def remove_internal_links(infobox_dict):
    print("\n--- Task 27: Remove Internal Link Tags ---")
    cleaned_dict = {}

    link_pattern = re.compile(r'\[\[(?:[^|\]]*\|)?([^\]]*)\]\]')

    for key, value in infobox_dict.items():
        cleaned_value = link_pattern.sub(r'\1', value)
        cleaned_dict[key] = cleaned_value
        print(f"{key}: {cleaned_value[:100]}..." if len(cleaned_value) > 100 else f"{key}: {cleaned_value}")

    return cleaned_dict

# Task 28: Remove Other MediaWiki Tags
def remove_other_wiki_tags(infobox_dict):
    print("\n--- Task 28: Remove Other MediaWiki Tags ---")
    cleaned_dict = {}

    template_pattern = re.compile(r'{{[^}]*}}')
    ref_pattern = re.compile(r'<ref[^>]*>.*?</ref>', re.DOTALL)
    html_pattern = re.compile(r'<[^>]+>')

    for key, value in infobox_dict.items():
        cleaned_value = template_pattern.sub('', value)
        cleaned_value = ref_pattern.sub('', cleaned_value)
        cleaned_value = html_pattern.sub('', cleaned_value)
        cleaned_value = re.sub(r'\s+', ' ', cleaned_value).strip()

        cleaned_dict[key] = cleaned_value
        print(f"{key}: {cleaned_value[:100]}..." if len(cleaned_value) > 100 else f"{key}: {cleaned_value}")

    return cleaned_dict

# Task 29: Get the Flag Image URL
def get_flag_image_url(infobox_dict, multimedia_files):
    print("\n--- Task 29: Get the Flag Image URL ---")

    flag_keys = ['flag', 'image_flag']
    flag_file = None

    for key in flag_keys:
        if key in infobox_dict:
            match = re.search(r'([^/|]+\.(?:svg|png|jpg|jpeg))', infobox_dict[key], re.IGNORECASE)
            if match:
                flag_file = match.group(1)
                break

    if not flag_file:
        for file in multimedia_files:
            if 'flag' in file.lower():
                flag_file = file
                break

    if not flag_file:
        print("Flag image not found")
        return None

    print(f"Flag file: {flag_file}")

    # Clean the filename
    flag_file = flag_file.replace(' ', '_')

    api_url = "https://en.wikipedia.org/w/api.php"
    params = {
        "action": "query",
        "format": "json",
        "titles": f"File:{flag_file}",
        "prop": "imageinfo",
        "iiprop": "url"
    }

    try:
        response = requests.get(api_url, params=params)
        data = response.json()

        pages = data["query"]["pages"]
        for page_id in pages:
            if "imageinfo" in pages[page_id]:
                image_url = pages[page_id]["imageinfo"][0]["url"]
                print(f"Flag image URL: {image_url}")
                return image_url

        print("Could not retrieve image URL from API")
        return None

    except Exception as e:
        print(f"Error retrieving image URL: {e}")
        return None

# Main function to run all tasks
def process_wikipedia_article(filename, article_title):
    # Task 20
    article = read_wiki_article(filename, article_title)

    if article:
        article_text = article['text']

        # Tasks 21-22
        category_lines = extract_category_lines(article_text)
        category_names = extract_category_names(category_lines)

        # Task 23
        section_info = extract_section_structure(article_text)

        # Task 24
        multimedia_files = extract_multimedia(article_text)

        # Tasks 25-28
        infobox_dict = extract_infobox(article_text)
        cleaned_infobox1 = remove_emphasis_tags(infobox_dict)
        cleaned_infobox2 = remove_internal_links(cleaned_infobox1)
        final_infobox = remove_other_wiki_tags(cleaned_infobox2)

        # Task 29
        flag_url = get_flag_image_url(infobox_dict, multimedia_files)

        if flag_url:
            display(HTML(f'<img src="{flag_url}" alt="Flag of {article_title}" width="300">'))

process_wikipedia_article('enwiki-country.json.gz', 'United Kingdom')