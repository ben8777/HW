# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18hbExYrCWBJOVseVS2weAeas2bYyTieL
"""



"""# test

"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
import random
import os
import requests
import zipfile
import io

def seed_everything(seed=42):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)

def fetch_data(url: str, save_dir: str, filename: str) -> pd.DataFrame:
    req = requests.get(url)
    zip_file = zipfile.ZipFile(io.BytesIO(req.content))
    zip_file.extractall(save_dir)

    df = pd.read_csv(os.path.join(save_dir, filename), sep='\t', header=None)
    return df

def shape_data(df: pd.DataFrame):#-> (pd.DataFrame, pd.DataFrame, pd.DataFrame):
    df.columns = ['id', 'title', 'url', 'publisher', 'category', 'story', 'hostname', 'timestamp']
    df_cond = df[df['publisher'].isin(['Reuters' ,'Huffington Post',
                                        'Businessweek', 'Contactmusic.com', 'Daily Mail'])]
    df_train, df_val_test = train_test_split(df_cond, test_size=0.2)
    df_val, df_test = train_test_split(df_val_test, test_size=0.5)
    return df_train, df_val, df_test

def fetch_shape_data(url: str, save_dir: str, filename: str):# -> (pd.DataFrame, pd.DataFrame, pd.DataFrame):
    df = fetch_data(url=url, save_dir=save_dir, filename=filename)
    train_df, valid_df, test_df = shape_data(df=df)
    return train_df, valid_df, test_df

if __name__ == '__main__':
    seed_everything(seed=42)
    url = "https://archive.ics.uci.edu/static/public/359/news+aggregator.zip"
    save_dir = './data/'
    filename = 'newsCorpora.csv'
    df_train, df_val, df_test = fetch_shape_data(url=url,
                                            save_dir=save_dir,
                                            filename=filename)
    df_train.to_csv(os.path.join(save_dir, 'train.txt'), sep='\t',
                    index=None)
    df_val.to_csv(os.path.join(save_dir, 'val.txt'), sep='\t',
                    index=None)
    df_test.to_csv(os.path.join(save_dir, 'test.txt'), sep='\t',
                    index=None)
    print('df_train record size:', len(df_train))
    print('df_val record size:', len(df_val))
    print('df_test record size:', len(df_test))

"""51"""

import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer

class FeatureExtractor:
    def __init__(self):
        self.vectorizer = TfidfVectorizer()

    def extract_features(self, df: pd.DataFrame,
                        is_test: bool) -> np.array:
        if is_test:
            X = self.vectorizer.transform(df['title']).toarray()
        else:
            X = self.vectorizer.fit_transform(df['title']).toarray()
        return X

    def extract_save_features(self,
                            df: pd.DataFrame,
                            is_test: bool,
                            filepath: str) -> None:
        array = self.extract_features(df, is_test=is_test)
        np.save(file=filepath, arr=array, allow_pickle=True)

if __name__ == '__main__':

    train_path = './data/train.txt'
    val_path = './data/val.txt'
    test_path = './data/test.txt'

    fe = FeatureExtractor()

    df_train = pd.read_csv(train_path, sep='\t')
    train_fe_path = train_path.replace('.txt', '_features.npy')
    fe.extract_save_features(df_train, is_test=False,
                             filepath=train_fe_path)

    df_val = pd.read_csv(val_path, sep='\t')
    val_fe_path = val_path.replace('.txt', '_features.npy')
    fe.extract_save_features(df_val, is_test=True,
                             filepath=val_fe_path)

    df_test = pd.read_csv(test_path, sep='\t')
    test_fe_path = test_path.replace('.txt', '_features.npy')
    fe.extract_save_features(df_test, is_test=True,
                             filepath=test_fe_path)

"""52"""

import numpy as np
import pandas as pd
from sklearn import preprocessing
from sklearn.linear_model import LogisticRegression
import random
import os
import pickle
from typing import Union

def preprocess_label(label_path: str) -> Union[np.array, preprocessing.LabelEncoder]:
    df = pd.read_csv(label_path, sep='\t')
    le = preprocessing.LabelEncoder()
    le.fit(df['category'])
    return le.transform(df['category']), le

def train(x_train: np.array, y: np.array) -> LogisticRegression:
    clf = LogisticRegression().fit(x_train, y)
    return clf

if __name__ == '__main__':
    label_path = './data/train.txt'
    train_path = './data/train_features.npy'
    model_path = './data/model_logisticregression.pickle'

    y, le = preprocess_label(label_path=label_path)
    x_train = np.load(file=train_path)
    clf = train(x_train=x_train, y=y)
    with open(model_path, 'wb') as f:
        pickle.dump(clf, f)
    print('Training done.')

"""53

"""

import numpy as np
import pandas as pd
from sklearn import preprocessing
from sklearn.linear_model import LogisticRegression
import random
import os
import pickle

def preprocess_label(label_path: str):
    df = pd.read_csv(label_path, sep='\t')
    le = preprocessing.LabelEncoder()
    le.fit(df['category'])
    return le.transform(df['category']), le

def train(x_train: np.array, y: np.array) -> LogisticRegression:
    clf = LogisticRegression().fit(x_train, y)
    return clf

if __name__ == '__main__':
    label_path = './data/train.txt'
    train_path = './data/train_features.npy'
    model_path = './data/model_logisticregression.pickle'
    y, le = preprocess_label(label_path=label_path)

    with open(model_path, 'rb') as f:
        clf = pickle.load(f)

    val_path = './data/val_features.npy'
    x_val = np.load(file=val_path)
    cl_label = clf.predict(x_val)
    print('The model predicted as :', le.inverse_transform(np.array(cl_label)))
    proba = clf.predict_proba(x_val)
    print('The probabilities are:', proba)

"""54

"""

import numpy as np
import pickle
from sklearn import preprocessing
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import pandas as pd

def preprocess_label(label_path: str):
    df = pd.read_csv(label_path, sep='\t')
    le = preprocessing.LabelEncoder()
    le.fit(df['category'])
    return le.transform(df['category']), le

if __name__ == '__main__':
    model_path = './data/model_logisticregression.pickle'
    train_path = './data/train.txt'
    test_fe_path = './data/test_features.npy'
    test_path = './data/test.txt'

    with open(model_path, 'rb') as f:
        clf = pickle.load(f)
    _, le = preprocess_label(label_path=train_path)
    df_test = pd.read_csv(test_path, sep='\t')

    x_test = np.load(file=test_fe_path)
    y_pred = clf.predict(x_test)

    y_true = le.transform(df_test['category'])
    print('Accuracy score:', accuracy_score(y_true, y_pred))

"""55

"""

import numpy as np
import pickle
from sklearn import preprocessing
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay
import pandas as pd
import matplotlib.pyplot as plt

def preprocess_label(label_path: str):
    df = pd.read_csv(label_path, sep='\t')
    le = preprocessing.LabelEncoder()
    le.fit(df['category'])
    return le.transform(df['category']), le

if __name__ == '__main__':
    model_path = './data/model_logisticregression.pickle'
    train_path = './data/train.txt'
    test_fe_path = './data/test_features.npy'
    test_path = './data/test.txt'
    fig_path = './data/confusion_matrix.png'

    with open(model_path, 'rb') as f:
        clf = pickle.load(f)
    _, le = preprocess_label(label_path=train_path)
    df_test = pd.read_csv(test_path, sep='\t')

    x_test = np.load(file=test_fe_path)
    y_true = le.transform(df_test['category'])

    ConfusionMatrixDisplay.from_estimator(estimator=clf, X=x_test, y=y_true,
                                         display_labels=le.classes_)

    plt.savefig(fname=fig_path)

"""56"""

import numpy as np
import pickle
from sklearn import preprocessing
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import precision_recall_fscore_support
import pandas as pd
import matplotlib.pyplot as plt

def preprocess_label(label_path: str):
    df = pd.read_csv(label_path, sep='\t')
    le = preprocessing.LabelEncoder()
    le.fit(df['category'])
    return le.transform(df['category']), le

if __name__ == '__main__':
    model_path = './data/model_logisticregression.pickle'
    train_path = './data/train.txt'
    test_fe_path = './data/test_features.npy'
    test_path = './data/test.txt'
    fig_path = './data/confusion_matrix.png'

    with open(model_path, 'rb') as f:
        clf = pickle.load(f)
    _, le = preprocess_label(label_path=train_path)
    df_test = pd.read_csv(test_path, sep='\t')

    x_test = np.load(file=test_fe_path)
    y_true = le.transform(df_test['category'])
    y_pred = clf.predict(x_test)
    print(le.classes_)
    result = precision_recall_fscore_support(y_true, y_pred, average=None,
                                    labels=le.transform(le.classes_))

    print('Precision:', result[0])
    print('Recall:', result[1])
    print('F1:', result[2])

"""57"""

import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn import preprocessing
from typing import Union
import pickle

class FeatureExtractor:
    def __init__(self):
        self.vectorizer = TfidfVectorizer()

    def extract_features(self, df: pd.DataFrame,
                        is_test: bool) -> np.array:
        if is_test:
            X = self.vectorizer.transform(df['title']).toarray()
        else:
            X = self.vectorizer.fit_transform(df['title']).toarray()
        return X

    def extract_save_features(self,
                            df: pd.DataFrame,
                            is_test: bool,
                            filepath: str) -> None:
        array = self.extract_features(df, is_test=is_test)
        np.save(file=filepath, arr=array, allow_pickle=True)

def preprocess_label(label_path: str) -> Union[np.array, preprocessing.LabelEncoder]:
    df = pd.read_csv(label_path, sep='\t')
    le = preprocessing.LabelEncoder()
    le.fit(df['category'])
    return le.transform(df['category']), le

if __name__ == '__main__':

    train_path = './data/train.txt'
    val_path = './data/val.txt'
    test_path = './data/test.txt'

    fe = FeatureExtractor()

    df_train = pd.read_csv(train_path, sep='\t')
    train_fe_path = train_path.replace('.txt', '_features.npy')
    fe.extract_save_features(df_train, is_test=False,
                             filepath=train_fe_path)

    model_path = './data/model_logisticregression.pickle'
    y, le = preprocess_label(label_path=train_path)
    with open(model_path, 'rb') as f:
        clf = pickle.load(f)

    # Use get_feature_names_out() instead of get_feature_names()
    feature_names = fe.vectorizer.get_feature_names_out()
    for i, coef in enumerate(clf.coef_):
        print('===TOP10 weights for class {}==='.format(
            le.classes_[i]
        ))
        top10_indices = coef.argsort()[-10:][::-1]
        for idx in top10_indices:
            print(feature_names[idx])
    for i, coef in enumerate(clf.coef_):
        print('===LEAST10 weights for class {}==='.format(
            le.classes_[i]
        ))
        top10_indices = coef.argsort()[:10]
        for idx in top10_indices:
            print(feature_names[idx])

"""58"""

import numpy as np
import pandas as pd
from sklearn import preprocessing
from sklearn.linear_model import LogisticRegression
import random
import os
import pickle
from typing import Union
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

def preprocess_label(label_path: str) -> Union[np.array, preprocessing.LabelEncoder]:
    df = pd.read_csv(label_path, sep='\t')
    le = preprocessing.LabelEncoder()
    le.fit(df['category'])
    return le.transform(df['category']), le

def train(x_train: np.array, y: np.array, C: float) -> LogisticRegression:
    clf = LogisticRegression(C=C).fit(x_train, y)
    return clf

if __name__ == '__main__':
    label_path = './data/train.txt'
    train_path = './data/train_features.npy'
    model_path = './data/model_logisticregression.pickle'

    val_path = './data/val.txt'
    test_path = './data/test.txt'

    fig_path = './data/acc_vs_param.png'

    y, le = preprocess_label(label_path=label_path)
    x_train = np.load(file=train_path)

    df_train = pd.read_csv(label_path, sep='\t')
    df_val = pd.read_csv(val_path, sep='\t')
    df_test = pd.read_csv(test_path, sep='\t')

    reguralization_parameters = [0.01, 0.03, 0.1, 0.3, 1, 3, 10]
    val_fe_path = './data/val_features.npy'
    test_fe_path = './data/test_features.npy'
    x_val = np.load(file=val_fe_path)
    x_test = np.load(file=test_fe_path)

    y_true_train = le.transform(df_train['category'])
    y_true_val = le.transform(df_val['category'])
    y_true_test = le.transform(df_test['category'])

    acc_tr, acc_val, acc_test = [], [], []
    for C in reguralization_parameters:
        clf = train(x_train=x_train, y=y, C=C)

        y_pred = clf.predict(x_train)
        acc_tr.append(accuracy_score(y_true_train, y_pred))

        y_pred = clf.predict(x_val)
        acc_val.append(accuracy_score(y_true_val, y_pred))

        y_pred = clf.predict(x_test)
        acc_test.append(accuracy_score(y_true_test, y_pred))

    plt.plot(reguralization_parameters, acc_tr,
            color='blue', marker='o', label='train')
    plt.plot(reguralization_parameters, acc_val,
            color='green', marker='+', label='val')
    plt.plot(reguralization_parameters, acc_test,
            color='red', marker='^', label='test')

    plt.xlabel('Regularization parameter C')
    plt.ylabel('Accuracy')
    plt.legend(bbox_to_anchor=(1, 0), loc='lower right', borderaxespad=1)

    plt.savefig(fig_path)

"""59"""

import numpy as np
import pandas as pd
from sklearn import preprocessing
from sklearn.linear_model import LogisticRegression
import random
import os
import pickle
from typing import Union
from sklearn.metrics import accuracy_score
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
import wandb
import xgboost as xgb

def seed_everything(seed=42):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)

def preprocess_label(label_path: str) -> Union[np.array, preprocessing.LabelEncoder]:
    df = pd.read_csv(label_path, sep='\t')
    le = preprocessing.LabelEncoder()
    le.fit(df['category'])
    return le.transform(df['category']), le

def train(x_train: np.array, y: np.array, C: float,
            model_type: str):
    if model_type == 'LR':
        clf = LogisticRegression(C=C).fit(x_train, y)
    elif model_type == 'NB':
        clf = MultinomialNB(alpha=C).fit(x_train, y)
    elif model_type == 'RF':
        clf = RandomForestClassifier(n_estimators=int(C*100))
        clf.fit(x_train, y)
    else:
        raise ValueError
    return clf

if __name__ == '__main__':
    seed_everything()

    # wandb.init(project='visualize-sklearn')

    label_path = './data/train.txt'
    train_path = './data/train_features.npy'
    model_path = './data/model_logisticregression.pickle'

    val_path = './data/val.txt'
    test_path = './data/test.txt'

    fig_path = './data/acc_vs_param.png'

    y, le = preprocess_label(label_path=label_path)
    x_train = np.load(file=train_path)

    df_train = pd.read_csv(label_path, sep='\t')
    df_val = pd.read_csv(val_path, sep='\t')
    df_test = pd.read_csv(test_path, sep='\t')

    reguralization_parameters = [0.01, 0.03, 0.1, 0.3, 1, 3, 10]
    val_fe_path = './data/val_features.npy'
    test_fe_path = './data/test_features.npy'
    x_val = np.load(file=val_fe_path)
    x_test = np.load(file=test_fe_path)

    y_true_train = le.transform(df_train['category'])
    y_true_val = le.transform(df_val['category'])
    y_true_test = le.transform(df_test['category'])

    model_type = 'NB' #['NB', 'LR', 'SVC'] # LogisticRegression, SupportVectorClassifier, NaiveBayes
    C = 0.03

    clf = train(x_train=x_train, y=y, C=C, model_type=model_type)

    y_pred = clf.predict(x_test)
    acc = accuracy_score(y_true_test, y_pred)

    print(acc, model_type, C)